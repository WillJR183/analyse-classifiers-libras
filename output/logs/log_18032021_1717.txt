[INFO][INICIO] executando Script...
20210318_1718

[INFO] preparando e aumentando conjunto de dados...

Found 27774 images belonging to 21 classes.
Found 6940 images belonging to 21 classes.
Found 11548 images belonging to 21 classes.
[INFO] informações dos dados de treino...

image batch shape:  (32, 64, 64, 3)
label batch shape:  (32, 21)
['A' 'B' 'C' 'D' 'E' 'F' 'G' 'I' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U'
 'V' 'W' 'Y']

[INFO] compilando o modelo...


[INFO] imprimindo estrutura do modelo...

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 64, 64, 16)        448       
_________________________________________________________________
activation (Activation)      (None, 64, 64, 16)        0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 32, 32, 16)        0         
_________________________________________________________________
dropout (Dropout)            (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 30, 30, 32)        4640      
_________________________________________________________________
activation_1 (Activation)    (None, 30, 30, 32)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 15, 15, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     
_________________________________________________________________
activation_2 (Activation)    (None, 13, 13, 64)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 6, 6, 64)          0         
_________________________________________________________________
flatten (Flatten)            (None, 2304)              0         
_________________________________________________________________
dense (Dense)                (None, 64)                147520    
_________________________________________________________________
dropout_3 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 21)                1365      
_________________________________________________________________
activation_3 (Activation)    (None, 21)                0         
=================================================================
Total params: 172,469
Trainable params: 172,469
Non-trainable params: 0
_________________________________________________________________

[INFO] treinando o modelo...

Epoch 1/50
868/868 - 79s - loss: 1.8275 - acc: 0.4005 - val_loss: 1.0116 - val_acc: 0.6911
Epoch 2/50
868/868 - 77s - loss: 0.8840 - acc: 0.6802 - val_loss: 0.7212 - val_acc: 0.7549
Epoch 3/50
868/868 - 79s - loss: 0.6685 - acc: 0.7551 - val_loss: 0.6062 - val_acc: 0.7952
Epoch 4/50
868/868 - 86s - loss: 0.5365 - acc: 0.7983 - val_loss: 0.5880 - val_acc: 0.8183
Epoch 5/50
868/868 - 79s - loss: 0.4392 - acc: 0.8343 - val_loss: 0.4867 - val_acc: 0.8503
Epoch 6/50
868/868 - 78s - loss: 0.3794 - acc: 0.8591 - val_loss: 0.4877 - val_acc: 0.8455
Epoch 7/50
868/868 - 80s - loss: 0.3373 - acc: 0.8768 - val_loss: 0.6411 - val_acc: 0.8441
Epoch 8/50
868/868 - 83s - loss: 0.2976 - acc: 0.8905 - val_loss: 0.4791 - val_acc: 0.8703
Epoch 9/50
868/868 - 84s - loss: 0.2629 - acc: 0.9025 - val_loss: 0.4646 - val_acc: 0.8774
Epoch 10/50
868/868 - 80s - loss: 0.2367 - acc: 0.9126 - val_loss: 0.4760 - val_acc: 0.8682
Epoch 11/50
868/868 - 79s - loss: 0.2124 - acc: 0.9208 - val_loss: 0.4446 - val_acc: 0.8790
Epoch 12/50
868/868 - 78s - loss: 0.1953 - acc: 0.9282 - val_loss: 0.4995 - val_acc: 0.8790
Epoch 13/50
868/868 - 78s - loss: 0.1862 - acc: 0.9311 - val_loss: 0.4470 - val_acc: 0.8872
Epoch 14/50
868/868 - 78s - loss: 0.1799 - acc: 0.9357 - val_loss: 0.4357 - val_acc: 0.8939
Epoch 15/50
868/868 - 78s - loss: 0.1586 - acc: 0.9422 - val_loss: 0.4102 - val_acc: 0.9029
Epoch 16/50
868/868 - 80s - loss: 0.1483 - acc: 0.9466 - val_loss: 0.4919 - val_acc: 0.8850
Epoch 17/50
868/868 - 79s - loss: 0.1395 - acc: 0.9496 - val_loss: 0.4384 - val_acc: 0.8908
Epoch 18/50
868/868 - 77s - loss: 0.1270 - acc: 0.9521 - val_loss: 0.4581 - val_acc: 0.8928
Epoch 19/50
868/868 - 78s - loss: 0.1310 - acc: 0.9537 - val_loss: 0.5144 - val_acc: 0.8912
Epoch 20/50
868/868 - 77s - loss: 0.1228 - acc: 0.9549 - val_loss: 0.4711 - val_acc: 0.8958
Epoch 21/50
868/868 - 79s - loss: 0.1144 - acc: 0.9603 - val_loss: 0.4397 - val_acc: 0.8997
Epoch 22/50
868/868 - 78s - loss: 0.1088 - acc: 0.9614 - val_loss: 0.4276 - val_acc: 0.9043
Epoch 23/50
868/868 - 80s - loss: 0.1160 - acc: 0.9592 - val_loss: 0.5271 - val_acc: 0.8961
Epoch 24/50
868/868 - 81s - loss: 0.1004 - acc: 0.9644 - val_loss: 0.4896 - val_acc: 0.8950
Epoch 25/50
868/868 - 77s - loss: 0.0917 - acc: 0.9671 - val_loss: 0.5054 - val_acc: 0.9012
Epoch 26/50
868/868 - 77s - loss: 0.0945 - acc: 0.9668 - val_loss: 0.4289 - val_acc: 0.9072
Epoch 27/50
868/868 - 77s - loss: 0.0889 - acc: 0.9687 - val_loss: 0.4260 - val_acc: 0.9078
Epoch 28/50
868/868 - 78s - loss: 0.0856 - acc: 0.9694 - val_loss: 0.4589 - val_acc: 0.9059
Epoch 29/50
868/868 - 78s - loss: 0.0826 - acc: 0.9713 - val_loss: 0.4741 - val_acc: 0.9117
Epoch 30/50
868/868 - 76s - loss: 0.0818 - acc: 0.9709 - val_loss: 0.4455 - val_acc: 0.9150
Epoch 31/50
868/868 - 82s - loss: 0.0790 - acc: 0.9728 - val_loss: 0.4615 - val_acc: 0.9055
Epoch 32/50
868/868 - 80s - loss: 0.0744 - acc: 0.9747 - val_loss: 0.4819 - val_acc: 0.9141
Epoch 33/50
868/868 - 77s - loss: 0.0734 - acc: 0.9741 - val_loss: 0.5446 - val_acc: 0.9081
Epoch 34/50
868/868 - 77s - loss: 0.0702 - acc: 0.9756 - val_loss: 0.5404 - val_acc: 0.9098
Epoch 35/50
868/868 - 78s - loss: 0.0701 - acc: 0.9751 - val_loss: 0.4574 - val_acc: 0.9110
Epoch 36/50
868/868 - 77s - loss: 0.0674 - acc: 0.9764 - val_loss: 0.5174 - val_acc: 0.9068
Epoch 37/50
868/868 - 77s - loss: 0.0676 - acc: 0.9768 - val_loss: 0.5471 - val_acc: 0.9111
Epoch 38/50
868/868 - 78s - loss: 0.0624 - acc: 0.9786 - val_loss: 0.4677 - val_acc: 0.9151
Epoch 39/50
868/868 - 83s - loss: 0.0681 - acc: 0.9770 - val_loss: 0.4268 - val_acc: 0.9271
Epoch 40/50
868/868 - 80s - loss: 0.0635 - acc: 0.9781 - val_loss: 0.4754 - val_acc: 0.9174
Epoch 41/50
868/868 - 79s - loss: 0.0645 - acc: 0.9783 - val_loss: 0.4362 - val_acc: 0.9135
Epoch 42/50
868/868 - 78s - loss: 0.0578 - acc: 0.9798 - val_loss: 0.4936 - val_acc: 0.9141
Epoch 43/50
868/868 - 78s - loss: 0.0574 - acc: 0.9806 - val_loss: 0.4053 - val_acc: 0.9215
Epoch 44/50
868/868 - 82s - loss: 0.0601 - acc: 0.9787 - val_loss: 0.4482 - val_acc: 0.9138
Epoch 45/50
868/868 - 83s - loss: 0.0562 - acc: 0.9804 - val_loss: 0.4885 - val_acc: 0.9105
Epoch 46/50
868/868 - 82s - loss: 0.0533 - acc: 0.9813 - val_loss: 0.5126 - val_acc: 0.9197
Epoch 47/50
868/868 - 83s - loss: 0.0562 - acc: 0.9813 - val_loss: 0.4812 - val_acc: 0.9086
Epoch 48/50
868/868 - 82s - loss: 0.0553 - acc: 0.9809 - val_loss: 0.4725 - val_acc: 0.9160
Epoch 49/50
868/868 - 83s - loss: 0.0515 - acc: 0.9819 - val_loss: 0.5047 - val_acc: 0.9107
Epoch 50/50
868/868 - 82s - loss: 0.0537 - acc: 0.9823 - val_loss: 0.4797 - val_acc: 0.9182

[INFO] salvando o modelo...

[INFO] modelo: output/models/cnn_model_libras_v1_20210318_1825.h5 salvo
[INFO] tempo de execução do modelo: 66.3 min
[INFO] informações dos dados de teste...

validation batch shape:  (32, 64, 64, 3)
label batch shape:  (32, 21)
['A' 'B' 'C' 'D' 'E' 'F' 'G' 'I' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U'
 'V' 'W' 'Y']

[INFO] avaliando o modelo...


1/1 [==============================] - ETA: 0s - loss: 2.9082e-05 - acc: 1.0000
1/1 [==============================] - 0s 0s/step - loss: 2.9082e-05 - acc: 1.0000
Perda do teste:  2.9082171749905683e-05
Acurácia do teste:  1.0

Confusion Matrix

[[572   0   0   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0]
 [  0 562   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0]
 [  0   0 583   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0]
 [  0   0   0 533   0   0   0  17   0   0   0   0   0   0   0   0   0   0
    0   0   0]
 [ 25  18   0   0 527   0   3   1   0   0   0   0   0   0   0   0   0   0
    0   0   0]
 [  0   0   0   0   0 441   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   9]
 [  0   0   0   0   0   0 549   1   0   0   0   0   0   0   0   0   0   0
    0   0   0]
 [  0   0   0  10   0   0   0 540   0   0   0   0   0   0   0   0   0   0
    0   0   0]
 [  0   0   0   0   0   0   0   0 550   0   0   0   0   0   0   0   0   0
    0   0   0]
 [  0   0   0   0   0   0   0   0   0 498  43   0   0   9   0   0   0   0
    0   0   0]
 [  0   4   0   0   0   0   0   0   0  42 488   0   0  16   0   0   0   0
    0   0   0]
 [ 38   0  40   0   0   0   0   0   0   0   0 472   0   0   0   0   0   0
    0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0 550   0   0   0   0   0
    0   0   0]
 [  0   0   0   0   0   0   0   0   0   0  38   0   0 512   0   0   0   0
    0   0   0]
 [  0   0   0  53   0   0   0   0   0   0   0   0   0   0 494   0   0   0
    3   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 550   0   0
    0   0   0]
 [  0   0   0   0   0  51   0   2   0   0   0   0   0   0   0   0 438   0
    0  59   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 550
    0   0   0]
 [  0   0   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0
  544   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0 550   0]
 [  0   0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   0
    0   0 542]]

Quantidade total de amostras de teste:  11548

Classification Report

              precision    recall  f1-score   support

           A       0.90      0.99      0.94       579
           B       0.96      1.00      0.98       562
           C       0.94      1.00      0.97       583
           D       0.89      0.97      0.93       550
           E       0.99      0.92      0.95       574
           F       0.90      0.98      0.94       450
           G       0.99      1.00      1.00       550
           I       0.95      0.98      0.97       550
           L       1.00      1.00      1.00       550
           M       0.92      0.91      0.91       550
           N       0.86      0.89      0.87       550
           O       1.00      0.86      0.92       550
           P       1.00      1.00      1.00       550
           Q       0.95      0.93      0.94       550
           R       1.00      0.90      0.95       550
           S       1.00      1.00      1.00       550
           T       1.00      0.80      0.89       550
           U       1.00      1.00      1.00       550
           V       0.99      0.99      0.99       550
           W       0.90      1.00      0.95       550
           Y       0.98      0.99      0.98       550

    accuracy                           0.96     11548
   macro avg       0.96      0.96      0.96     11548
weighted avg       0.96      0.96      0.96     11548

[INFO] salvando matriz de confusão...
[INFO] plottando gráficos...

[INFO] gerando imagem do modelo de camadas...

[INFO] [FIM]20210318_1825
